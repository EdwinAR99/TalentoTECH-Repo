{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOYWIIAmr9muLOg/5hP0d9L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EdwinAR99/TalentoTECH-Repo/blob/master/Introduction_NLTK_TalentoTECH.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPORT LIBS"
      ],
      "metadata": {
        "id": "7SCsigaBFizT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "LHWijEodEd0s"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk import pos_tag\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords, movie_reviews\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.classify.scikitlearn import SklearnClassifier\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "import keras\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DOWNLOAD PACKAGES"
      ],
      "metadata": {
        "id": "mItM2mxIa5ND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('movie_reviews')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7iFgB3za9pC",
        "outputId": "fd501914-7f39-4fc6-bc51-7caeed6a4faa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TUTORIAL NLTK"
      ],
      "metadata": {
        "id": "v9uazmTJFnWS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenización"
      ],
      "metadata": {
        "id": "PqF4v-HNGonr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"NLTK es una biblioteca de procesamiento de lenguaje natural\"\n",
        "tokens = word_tokenize(sentence)\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jL-Vv6A-FqRC",
        "outputId": "102caf7c-f74f-4158-82b2-abaef0c5118f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['NLTK', 'es', 'una', 'biblioteca', 'de', 'procesamiento', 'de', 'lenguaje', 'natural']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Derivacion"
      ],
      "metadata": {
        "id": "r0RfS0nMHD7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"running\", \"plays\", \"jumped\"]\n",
        "stemmer = PorterStemmer()\n",
        "stems = [stemmer.stem(word) for word in words]\n",
        "print(stems)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWKirnYwGx9D",
        "outputId": "cd50946d-6770-4415-e824-a55e00d2a386"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['run', 'play', 'jump']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Etiquetado"
      ],
      "metadata": {
        "id": "as4AzFNPHYCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xz6yoe1jHZ0p",
        "outputId": "49ffae2e-1632-465f-af6a-e2c0ae951446"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"NLTK es una biblioteca de procesamiento de lenguaje natural\"\n",
        "tokens = word_tokenize(sentence)\n",
        "tagged_words = pos_tag(tokens)\n",
        "print(tagged_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VT7P_NOJHnx7",
        "outputId": "350fcd1e-5b2e-4977-b0f3-7f2fb1c3d7a7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('NLTK', 'NNP'), ('es', 'CC'), ('una', 'JJ'), ('biblioteca', 'NN'), ('de', 'IN'), ('procesamiento', 'FW'), ('de', 'FW'), ('lenguaje', 'FW'), ('natural', 'JJ')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classifier"
      ],
      "metadata": {
        "id": "zqlYzltwIcUE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    (\"Qué hermoso día hace hoy.\", \"positivo\"),\n",
        "    (\"No puedo soportar este calor sofocante.\", \"negativo\"),\n",
        "    (\"Me encanta pasar tiempo con mis amigos.\", \"positivo\"),\n",
        "    (\"El tráfico de la ciudad me pone de mal humor.\", \"negativo\"),\n",
        "    (\"La comida en este restaurante es deliciosa.\", \"positivo\"),\n",
        "    (\"Estoy cansado de esta rutina diaria.\", \"negativo\"),\n",
        "    (\"Disfruto mucho practicando deporte al aire libre.\", \"positivo\"),\n",
        "    (\"El ruido constante de la construcción me molesta.\", \"negativo\"),\n",
        "    (\"Me siento emocionado por el próximo concierto.\", \"positivo\"),\n",
        "    (\"Odio cuando la gente no respeta las normas de convivencia.\", \"negativo\"),\n",
        "    (\"¡Qué bonita es esta canción!\", \"positivo\"),\n",
        "    (\"No puedo soportar la impuntualidad.\", \"negativo\"),\n",
        "    (\"Estoy agradecido por tener una familia amorosa.\", \"positivo\"),\n",
        "    (\"El servicio en este restaurante es terrible.\", \"negativo\"),\n",
        "    (\"Me encanta ver películas en el cine.\", \"positivo\"),\n",
        "    (\"No soporto la arrogancia de algunas personas.\", \"negativo\"),\n",
        "    (\"Hoy ha sido un día muy productivo.\", \"positivo\"),\n",
        "    (\"Estoy harto de este tiempo lluvioso.\", \"negativo\"),\n",
        "    (\"Me siento inspirado después de leer ese libro.\", \"positivo\"),\n",
        "    (\"La actitud positiva hace la diferencia.\", \"positivo\"),\n",
        "    (\"No puedo soportar la hipocresía.\", \"negativo\"),\n",
        "    (\"Estoy emocionado por el viaje que tenemos planeado.\", \"positivo\"),\n",
        "    (\"Este dolor de cabeza constante es insoportable.\", \"negativo\"),\n",
        "    (\"Adoro pasar tiempo con mis mascotas.\", \"positivo\"),\n",
        "    (\"La actitud negativa solo genera más problemas.\", \"negativo\"),\n",
        "    (\"Estoy feliz por los logros alcanzados.\", \"positivo\"),\n",
        "    (\"Me molesta cuando las personas son irrespetuosas.\", \"negativo\"),\n",
        "    (\"Este fin de semana ha sido realmente relajante.\", \"positivo\"),\n",
        "    (\"No soporto la falta de sinceridad.\", \"negativo\"),\n",
        "    (\"Me siento agradecido por la belleza de la naturaleza.\", \"positivo\"),\n",
        "]\n"
      ],
      "metadata": {
        "id": "oM9mkxdHIoVU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-processing of data: Tokenize and extraction of features\n",
        "def preprocess(text):\n",
        "  tokens = word_tokenize(text)\n",
        "  return {word: True for word in tokens}"
      ],
      "metadata": {
        "id": "7Gw5afK6JBHQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply pre-processing to data\n",
        "featuresets = [(preprocess(text), label) for (text, label) in sentences]"
      ],
      "metadata": {
        "id": "Tfo9hLjvJNkK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data in training and test sets\n",
        "train_set, test_set = featuresets[:20], featuresets[20:]"
      ],
      "metadata": {
        "id": "cJ4THNafKMlT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a classifier using Naive Bayes\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)"
      ],
      "metadata": {
        "id": "08kk6eCpKtjP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eval the classifier on the test set\n",
        "accuracy = nltk.classify.accuracy(classifier, test_set)\n",
        "print(\"Accuracy\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EO2Ox33DLS08",
        "outputId": "e408bd2f-accb-4cb4-9465-3fd0ac99626a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classify a new text\n",
        "new_text = \"No me gusta tu cabello\"\n",
        "new_text_features = preprocess(new_text)\n",
        "predicted_label = classifier.classify(new_text_features)\n",
        "print(\"Predicted label:\", predicted_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqzrDAiQLnYO",
        "outputId": "952e99e2-f222-4b0d-929d-c6cf0241357a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted label: negativo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preguntas de compresion\n",
        "\n",
        "\n",
        "1.   Qué tarea realiza el código proporcionado?\n",
        "    \n",
        "    *RTA/* Implementar un clasificador para diferenciar entre sentencias con sentimientos positivos y negativos, eso se hace utilizando la libreria nltk, y mas en especifico el clasificador Naive Bayes que contiene la libreria.\n",
        "2.   Cuál es el propósito del preprocesamiento de datos en este contexto?\n",
        "\n",
        "    *RTA/* El preprocesamiento de los datos se hace para que apartir de un conjunto de sentencias y su tipo de sentimiento, se puedan extraer sus caracteristicas y con ello puedan ser utilizadas para entrenar el clasificador Naive Bayes.\n",
        "3.   Qué función del NLTK se utiliza para tokenizar el texto?\n",
        "\n",
        "    *RTA/* Se utiliza el metodo word_tokenize.\n",
        "4.   Cuál es el proposito de dividir los datos en conjuntos de entrenamiento y prueba?\n",
        "\n",
        "    *RTA/* Un conjunto de utiliza para enseñarle al modelo como son las sentencias y el conjunto de prueba se usa para ver el rendimiento del modelo con datos que no conoce.\n",
        "5.   Qué algoritmo de clasificación se utiliza en este cóodigo?\n",
        "\n",
        "    *RTA/* Se usa Naive Bayes.\n",
        "6.   Cómo se evalúa la precisión del clasificador?\n",
        "\n",
        "    *RTA/* Con el conjunto de datos de pruebas utilizando el metodo accuracy de classify y de la libreria de nltk.\n",
        "7.   Qué se entiende por \"Accuracy\" en el contexto de la evaluacion del clasificador?\n",
        "\n",
        "    *RTA/* La precision es la cantidad de aciertos que tiene el modelo prediciendo las sentencias del conunto de pruebas.\n",
        "8.   Cuál es el resultado de la clasificación del nuevo texto \"This movie is amazing\"?\n",
        "\n",
        "    *RTA/* El modelo predice que la sentencia tiene un sentimiento positivo.\n",
        "\n"
      ],
      "metadata": {
        "id": "oQ3wr6e4M2sS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EXPLORATION EXERCISES"
      ],
      "metadata": {
        "id": "60GQ8kiJUHQZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modifica el conjunto datos agregando más instancias con comentarios de películas y etiquetas de sentimientos.\n"
      ],
      "metadata": {
        "id": "N-UCxMzcQgLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Comentarios de películas positivas\n",
        "positive_movie_comments = [\n",
        "    (\"Esta película es absolutamente encantadora.\", \"positivo\"),\n",
        "    (\"Me encantó cada minuto de esta película.\", \"positivo\"),\n",
        "    (\"La actuación de los protagonistas es excepcional.\", \"positivo\"),\n",
        "    (\"Es una de las mejores películas que he visto en mucho tiempo.\", \"positivo\"),\n",
        "    (\"La trama es emocionante y bien desarrollada.\", \"positivo\"),\n",
        "    (\"Los efectos visuales son impresionantes.\", \"positivo\"),\n",
        "    (\"La música complementa perfectamente cada escena.\", \"positivo\"),\n",
        "    (\"Me sentí completamente absorbido por la historia.\", \"positivo\"),\n",
        "    (\"Es una obra maestra del cine contemporáneo.\", \"positivo\"),\n",
        "    (\"Esta película me dejó con una sensación de felicidad duradera.\", \"positivo\"),\n",
        "    (\"Recomendaría esta película a cualquiera que busque una experiencia cinematográfica gratificante.\", \"positivo\"),\n",
        "    (\"La dirección es impecable.\", \"positivo\"),\n",
        "    (\"Los diálogos son inteligentes y conmovedores.\", \"positivo\"),\n",
        "    (\"La química entre los actores es palpable.\", \"positivo\"),\n",
        "    (\"Es una joya oculta que merece ser descubierta por más personas.\", \"positivo\"),\n",
        "    (\"Esta película superó todas mis expectativas.\", \"positivo\"),\n",
        "    (\"Es una historia conmovedora que te hace reflexionar sobre la vida.\", \"positivo\"),\n",
        "    (\"Cada escena es visualmente impresionante.\", \"positivo\"),\n",
        "    (\"No puedo esperar para verla de nuevo.\", \"positivo\"),\n",
        "    (\"Es una película que te deja con una sonrisa en el rostro.\", \"positivo\"),\n",
        "]\n",
        "\n",
        "# Comentarios de películas negativas\n",
        "negative_movie_comments = [\n",
        "    (\"Esta película es aburrida y predecible.\", \"negativo\"),\n",
        "    (\"No entiendo por qué recibió tantas críticas positivas.\", \"negativo\"),\n",
        "    (\"La trama es confusa y poco interesante.\", \"negativo\"),\n",
        "    (\"Los personajes carecen de profundidad y desarrollo.\", \"negativo\"),\n",
        "    (\"La actuación es mediocre en el mejor de los casos.\", \"negativo\"),\n",
        "    (\"Me decepcionó mucho esta película.\", \"negativo\"),\n",
        "    (\"Es una pérdida de tiempo y dinero.\", \"negativo\"),\n",
        "    (\"No logré conectar emocionalmente con ninguno de los personajes.\", \"negativo\"),\n",
        "    (\"La dirección es torpe y poco inspirada.\", \"negativo\"),\n",
        "    (\"Los efectos especiales son baratos y poco convincentes.\", \"negativo\"),\n",
        "    (\"La música es irritante y fuera de lugar.\", \"negativo\"),\n",
        "    (\"Es una de las peores películas que he tenido la desgracia de ver.\", \"negativo\"),\n",
        "    (\"No recomendaría esta película ni siquiera a mi peor enemigo.\", \"negativo\"),\n",
        "    (\"Es una película olvidable que no deja ninguna impresión duradera.\", \"negativo\"),\n",
        "    (\"Me quedé dormido a mitad de la película.\", \"negativo\"),\n",
        "    (\"La trama es tan predecible que sabía lo que iba a suceder antes de que ocurriera.\", \"negativo\"),\n",
        "    (\"Los diálogos son cursis y poco realistas.\", \"negativo\"),\n",
        "    (\"Es una película sin alma ni propósito.\", \"negativo\"),\n",
        "    (\"No puedo entender cómo esta película recibió financiamiento para ser realizada.\", \"negativo\"),\n",
        "    (\"Es un desastre cinematográfico en todos los sentidos.\", \"negativo\"),\n",
        "]\n",
        "\n",
        "# Concatenando todas las instancias\n",
        "movie_sentences = positive_movie_comments + negative_movie_comments + sentences\n",
        "\n",
        "# Ordenar de forma aleatoria\n",
        "random.shuffle(movie_sentences)"
      ],
      "metadata": {
        "id": "LTfNErHKUKpq"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experimenta con diferentes técnicas de preprocesamiento de texto, como eliminación de stopwords o lematización, y observa cómo afecta la precisión del clasicador."
      ],
      "metadata": {
        "id": "5QQjQtsZTCMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener la lista de stopwords en español\n",
        "stop_words = set(stopwords.words('spanish'))\n",
        "\n",
        "# Inicializar el lematizador\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Función para preprocesar el texto\n",
        "def preprocess_text(text):\n",
        "    # Tokenizar el texto en palabras\n",
        "    words = word_tokenize(text)\n",
        "\n",
        "    # Eliminar stopwords y convertir a minúsculas\n",
        "    filtered_words = [word.lower() for word in words if word.lower() not in stop_words]\n",
        "\n",
        "    # Lematizar las palabras\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
        "\n",
        "    # Unir las palabras preprocesadas en un solo texto\n",
        "    preprocessed_text = ' '.join(lemmatized_words)\n",
        "\n",
        "    return preprocessed_text\n",
        "\n",
        "# Aplicar preprocesamiento a todas las instancias de texto\n",
        "preprocessed_movie_sentences = [(preprocess_text(sentence), sentiment) for sentence, sentiment in movie_sentences]\n",
        "\n",
        "# Mostrar algunos ejemplos de texto preprocesado\n",
        "for sentence, sentiment in preprocessed_movie_sentences[:5]:\n",
        "    print(sentence, \"-\", sentiment)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBC2yK7TTClo",
        "outputId": "d8301417-273d-4de7-b0b8-036723965aa6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ruido constante construcción molesta . - negativo\n",
            "quedé dormido mitad película . - negativo\n",
            "siento inspirado después leer libro . - positivo\n",
            "harto tiempo lluvioso . - negativo\n",
            "trama emocionante bien desarrollada . - positivo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prueba otros algoritmos de clasificacion disponibles en NLTK, como clasificador de árboles de decisión o clasificador de máquinas de vectores de soporte (SVM), y compara sus resultados con el clasicador de Naive Bayes."
      ],
      "metadata": {
        "id": "NHLWcARKTIgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicar preprocesamiento a todas las instancias de texto\n",
        "preprocessed_movie_sentences = [(preprocess_text(sentence), sentiment) for sentence, sentiment in movie_sentences]\n",
        "\n",
        "# Dividir los datos en conjunto de entrenamiento y conjunto de prueba\n",
        "X = [text for text, label in preprocessed_movie_sentences]\n",
        "y = [label for text, label in preprocessed_movie_sentences]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Función para extraer características de texto\n",
        "def extract_features(text):\n",
        "    return {word: True for word in word_tokenize(text)}\n",
        "\n",
        "# Preparar datos en formato NLTK\n",
        "train_data = [(extract_features(text), label) for text, label in zip(X_train, y_train)]\n",
        "test_data = [(extract_features(text), label) for text, label in zip(X_test, y_test)]\n",
        "\n",
        "# Entrenar y evaluar clasificador Naive Bayes\n",
        "naive_bayes_classifier = nltk.NaiveBayesClassifier.train(train_data)\n",
        "naive_bayes_accuracy = nltk.classify.accuracy(naive_bayes_classifier, test_data)\n",
        "\n",
        "print(\"Naive Bayes Classifier Accuracy:\", naive_bayes_accuracy)\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Convertir las instancias preprocesadas a texto\n",
        "X_train_text = [' '.join(features) for features, label in train_data]\n",
        "X_test_text = [' '.join(features) for features, label in test_data]\n",
        "\n",
        "# Crear y ajustar el vectorizador TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train_text)\n",
        "X_test_tfidf = vectorizer.transform(X_test_text)\n",
        "\n",
        "# Entrenar clasificador de árboles de decisión\n",
        "decision_tree_classifier = DecisionTreeClassifier().fit(X_train_tfidf, y_train)\n",
        "decision_tree_predictions = decision_tree_classifier.predict(X_test_tfidf)\n",
        "decision_tree_accuracy = accuracy_score(y_test, decision_tree_predictions)\n",
        "\n",
        "print(\"Decision Tree Classifier Accuracy:\", decision_tree_accuracy)\n",
        "\n",
        "# Entrenar y evaluar clasificador SVM\n",
        "svm_classifier = SklearnClassifier(SVC(kernel='linear')).train(train_data)\n",
        "svm_predictions = svm_classifier.classify_many([features for features, label in test_data])\n",
        "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
        "\n",
        "print(\"SVM Classifier Accuracy:\", svm_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1_Qq8bUTax8",
        "outputId": "2cacf5a4-7f58-4ad0-e321-4b8ea860fc27"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Classifier Accuracy: 0.42857142857142855\n",
            "Decision Tree Classifier Accuracy: 0.42857142857142855\n",
            "SVM Classifier Accuracy: 0.42857142857142855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Crea una función para calcular métricas adicionales de evaluación del clasificador, como precisión, recall y F1-score, y aplícala al modelo entrenado."
      ],
      "metadata": {
        "id": "0ph5SDijTbPc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_classifier(y_true, y_pred):\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "    return precision, recall, f1"
      ],
      "metadata": {
        "id": "oI6otlZVf2zg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluar el clasificador Naive Bayes\n",
        "naive_bayes_predictions = naive_bayes_classifier.classify_many([features for features, label in test_data])\n",
        "precision_nb, recall_nb, f1_nb = evaluate_classifier(y_test, naive_bayes_predictions)\n",
        "\n",
        "print(\"Naive Bayes Classifier Metrics:\")\n",
        "print(\"Precision:\", precision_nb)\n",
        "print(\"Recall:\", recall_nb)\n",
        "print(\"F1-score:\", f1_nb)\n",
        "print()\n",
        "\n",
        "# Evaluar el clasificador de árboles de decisión\n",
        "precision_dt, recall_dt, f1_dt = evaluate_classifier(y_test, decision_tree_predictions)\n",
        "\n",
        "print(\"Decision Tree Classifier Metrics:\")\n",
        "print(\"Precision:\", precision_dt)\n",
        "print(\"Recall:\", recall_dt)\n",
        "print(\"F1-score:\", f1_dt)\n",
        "print()\n",
        "\n",
        "# Evaluar el clasificador SVM\n",
        "precision_svm, recall_svm, f1_svm = evaluate_classifier(y_test, svm_predictions)\n",
        "\n",
        "print(\"SVM Classifier Metrics:\")\n",
        "print(\"Precision:\", precision_svm)\n",
        "print(\"Recall:\", recall_svm)\n",
        "print(\"F1-score:\", f1_svm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9j3RlryTo3Y",
        "outputId": "f806f910-1358-4330-cbb3-bf0e8b85e854"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Classifier Metrics:\n",
            "Precision: 0.5047619047619047\n",
            "Recall: 0.42857142857142855\n",
            "F1-score: 0.42857142857142855\n",
            "\n",
            "Decision Tree Classifier Metrics:\n",
            "Precision: 0.7916666666666667\n",
            "Recall: 0.5\n",
            "F1-score: 0.44385026737967914\n",
            "\n",
            "SVM Classifier Metrics:\n",
            "Precision: 0.5047619047619047\n",
            "Recall: 0.42857142857142855\n",
            "F1-score: 0.42857142857142855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experimenta con la clasificación de nuevos textos ingresados manualmente y diferentes observa cómo el clasificador comentarios de películas."
      ],
      "metadata": {
        "id": "mtW6YZKKTpEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_text(classifier, text, vectorizer):\n",
        "    preprocessed_text = preprocess_text(text)\n",
        "    features = vectorizer.transform([preprocessed_text])\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "    features_dict = {}\n",
        "    for idx, feature_value in enumerate(features.toarray()[0]):\n",
        "        features_dict[feature_names[idx]] = feature_value\n",
        "\n",
        "    # Comprobar si es un clasificador de NLTK (Naive Bayes)\n",
        "    if hasattr(classifier, 'classify'):\n",
        "        return classifier.classify(features_dict)\n",
        "    # Si no, es un clasificador de scikit-learn\n",
        "    else:\n",
        "        return classifier.predict(features)[0]\n",
        "\n",
        "# Definir un texto de ejemplo para clasificar\n",
        "new_text = \"¡Qué increíble actuación! Realmente me conmovió.\"\n",
        "\n",
        "# Clasificar el texto usando cada clasificador\n",
        "naive_bayes_prediction = classify_text(naive_bayes_classifier, new_text, vectorizer)\n",
        "decision_tree_prediction = classify_text(decision_tree_classifier, new_text, vectorizer)\n",
        "svm_prediction = classify_text(svm_classifier, new_text, vectorizer)\n",
        "\n",
        "# Mostrar los resultados de la clasificación\n",
        "print(\"Texto de ejemplo:\", new_text)\n",
        "print(\"Naive Bayes Classifier Prediction:\", naive_bayes_prediction)\n",
        "print(\"Decision Tree Classifier Prediction:\", decision_tree_prediction)\n",
        "print(\"SVM Classifier Prediction:\", svm_prediction)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zb9mHjEAT89h",
        "outputId": "7b16548a-3a1e-4215-e4c0-0db93ac792ba"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto de ejemplo: ¡Qué increíble actuación! Realmente me conmovió.\n",
            "Naive Bayes Classifier Prediction: negativo\n",
            "Decision Tree Classifier Prediction: positivo\n",
            "SVM Classifier Prediction: positivo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_to_test = [\n",
        "    \"Esta película es emocionante y llena de acción.\",\n",
        "    \"El guion es realmente pobre y la trama es predecible.\",\n",
        "    \"La cinematografía en esta película es impresionante.\",\n",
        "    \"El desarrollo de los personajes es bastante superficial.\",\n",
        "    \"No recomendaría esta película a nadie.\",\n",
        "    \"Los efectos especiales son sorprendentes.\",\n",
        "    \"Me quedé dormido en medio de la película.\",\n",
        "    \"El final de la película fue inesperado y satisfactorio.\",\n",
        "    \"El ritmo de la película es lento y aburrido.\",\n",
        "    \"La música complementa perfectamente la atmósfera de la película.\",\n",
        "    \"Los diálogos son inteligentes y bien escritos.\",\n",
        "    \"El director logra transmitir una gran cantidad de emociones.\",\n",
        "    \"La química entre los actores principales es palpable.\",\n",
        "    \"El diseño de producción es visualmente deslumbrante.\",\n",
        "    \"No puedo dejar de pensar en esta película desde que la vi.\",\n",
        "    \"La película me dejó con muchas preguntas sin respuesta.\",\n",
        "    \"Es difícil seguir el argumento de la película.\",\n",
        "    \"La actuación del elenco es mediocre en el mejor de los casos.\",\n",
        "    \"La película me hizo reír y llorar en igual medida.\",\n",
        "    \"No puedo esperar para ver esta película de nuevo.\"\n",
        "]\n",
        "\n",
        "# Ciclo para clasificar cada sentencia\n",
        "for sentence in sentences_to_test:\n",
        "    print(\"Texto de ejemplo:\", sentence)\n",
        "    print(\"Naive Bayes Classifier Prediction:\", classify_text(naive_bayes_classifier, sentence, vectorizer))\n",
        "    print(\"Decision Tree Classifier Prediction:\", classify_text(decision_tree_classifier, sentence, vectorizer))\n",
        "    print(\"SVM Classifier Prediction:\", classify_text(svm_classifier, sentence, vectorizer))\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAOYy_bUgRbE",
        "outputId": "742cc819-50e0-4664-df22-587c3c0489b2"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto de ejemplo: Esta película es emocionante y llena de acción.\n",
            "Naive Bayes Classifier Prediction: negativo\n",
            "Decision Tree Classifier Prediction: positivo\n",
            "SVM Classifier Prediction: positivo\n",
            "\n",
            "Texto de ejemplo: El guion es realmente pobre y la trama es predecible.\n",
            "Naive Bayes Classifier Prediction: negativo\n",
            "Decision Tree Classifier Prediction: positivo\n",
            "SVM Classifier Prediction: negativo\n",
            "\n",
            "Texto de ejemplo: La cinematografía en esta película es impresionante.\n",
            "Naive Bayes Classifier Prediction: negativo\n",
            "Decision Tree Classifier Prediction: positivo\n",
            "SVM Classifier Prediction: positivo\n",
            "\n",
            "Texto de ejemplo: El desarrollo de los personajes es bastante superficial.\n",
            "Naive Bayes Classifier Prediction: negativo\n",
            "Decision Tree Classifier Prediction: negativo\n",
            "SVM Classifier Prediction: negativo\n",
            "\n",
            "Texto de ejemplo: No recomendaría esta película a nadie.\n",
            "Naive Bayes Classifier Prediction: negativo\n",
            "Decision Tree Classifier Prediction: positivo\n",
            "SVM Classifier Prediction: negativo\n",
            "\n",
            "Texto de ejemplo: Los efectos especiales son sorprendentes.\n",
            "Naive Bayes Classifier Prediction: negativo\n",
            "Decision Tree Classifier Prediction: negativo\n",
            "SVM Classifier Prediction: negativo\n",
            "\n",
            "Texto de ejemplo: Me quedé dormido en medio de la película.\n",
            "Naive Bayes Classifier Prediction: negativo\n",
            "Decision Tree Classifier Prediction: negativo\n",
            "SVM Classifier Prediction: negativo\n",
            "\n",
            "Texto de ejemplo: El final de la película fue inesperado y satisfactorio.\n",
            "Naive Bayes Classifier Prediction: negativo\n",
            "Decision Tree Classifier Prediction: positivo\n",
            "SVM Classifier Prediction: positivo\n",
            "\n",
            "Texto de ejemplo: El ritmo de la película es lento y aburrido.\n",
            "Naive Bayes Classifier Prediction: negativo\n",
            "Decision Tree Classifier Prediction: positivo\n",
            "SVM Classifier Prediction: positivo\n",
            "\n",
            "Texto de ejemplo: La música complementa perfectamente la atmósfera de la película.\n",
            "Naive Bayes Classifier Prediction: negativo\n",
            "Decision Tree Classifier Prediction: positivo\n",
            "SVM Classifier Prediction: positivo\n",
            "\n",
            "Texto de ejemplo: Los diálogos son inteligentes y bien escritos.\n",
            "Naive Bayes Classifier Prediction: negativo\n",
            "Decision Tree Classifier Prediction: positivo\n",
            "SVM Classifier Prediction: positivo\n",
            "\n",
            "Texto de ejemplo: El director logra transmitir una gran cantidad de emociones.\n",
            "Naive Bayes Classifier Prediction: negativo\n",
            "Decision Tree Classifier Prediction: positivo\n",
            "SVM Classifier Prediction: positivo\n",
            "\n",
            "Texto de ejemplo: La química entre los actores principales es palpable.\n",
            "Naive Bayes Classifier Prediction: negativo\n",
            "Decision Tree Classifier Prediction: positivo\n",
            "SVM Classifier Prediction: positivo\n",
            "\n",
            "Texto de ejemplo: El diseño de producción es visualmente deslumbrante.\n",
            "Naive Bayes Classifier Prediction: negativo\n",
            "Decision Tree Classifier Prediction: positivo\n",
            "SVM Classifier Prediction: positivo\n",
            "\n",
            "Texto de ejemplo: No puedo dejar de pensar en esta película desde que la vi.\n",
            "Naive Bayes Classifier Prediction: negativo\n",
            "Decision Tree Classifier Prediction: positivo\n",
            "SVM Classifier Prediction: negativo\n",
            "\n",
            "Texto de ejemplo: La película me dejó con muchas preguntas sin respuesta.\n",
            "Naive Bayes Classifier Prediction: negativo\n",
            "Decision Tree Classifier Prediction: positivo\n",
            "SVM Classifier Prediction: positivo\n",
            "\n",
            "Texto de ejemplo: Es difícil seguir el argumento de la película.\n",
            "Naive Bayes Classifier Prediction: negativo\n",
            "Decision Tree Classifier Prediction: positivo\n",
            "SVM Classifier Prediction: positivo\n",
            "\n",
            "Texto de ejemplo: La actuación del elenco es mediocre en el mejor de los casos.\n",
            "Naive Bayes Classifier Prediction: negativo\n",
            "Decision Tree Classifier Prediction: positivo\n",
            "SVM Classifier Prediction: positivo\n",
            "\n",
            "Texto de ejemplo: La película me hizo reír y llorar en igual medida.\n",
            "Naive Bayes Classifier Prediction: negativo\n",
            "Decision Tree Classifier Prediction: positivo\n",
            "SVM Classifier Prediction: positivo\n",
            "\n",
            "Texto de ejemplo: No puedo esperar para ver esta película de nuevo.\n",
            "Naive Bayes Classifier Prediction: negativo\n",
            "Decision Tree Classifier Prediction: positivo\n",
            "SVM Classifier Prediction: positivo\n",
            "\n"
          ]
        }
      ]
    }
  ]
}